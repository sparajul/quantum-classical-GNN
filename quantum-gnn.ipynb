{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70ae137-abd8-4344-ba4f-d35d20553c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/m3/python/3.11.11/tensorflow-2025.08.21/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted PyTorch Version: 2.9.1+cu128\n",
      "Formatted CUDA Version: 12.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning import LightningModule\n",
    "from torch_geometric.nn import aggr\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.optim as optim\n",
    "from torch_scatter import scatter_add\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from typing import List, Optional\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings \n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, Sigmoid\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from collections import namedtuple\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "import pennylane as qml\n",
    "\n",
    "TORCH = torch.__version__\n",
    "CUDA = torch.version.cuda\n",
    "\n",
    "print(f\"Formatted PyTorch Version: {TORCH}\")\n",
    "print(f\"Formatted CUDA Version: {CUDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f414c1c2-2c4c-41f3-9d08-916c3eab8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, home_dir, sub_dir, preprocess=True, hparams=None):\n",
    "        self.base_path = os.path.join(home_dir, sub_dir)\n",
    "        self.file_names = self._get_file_names()\n",
    "        self.preprocess = preprocess\n",
    "        self.hparams = hparams if hparams is not None else {}\n",
    "\n",
    "    def _get_file_names(self):\n",
    "        file_names = []\n",
    "        for file_name in os.listdir(self.base_path):\n",
    "            if file_name.endswith('.pyg'):  # Adjust this condition as needed\n",
    "                file_names.append(file_name)\n",
    "        return file_names\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = os.path.join(self.base_path, file_name)\n",
    "        #data = torch.load(file_path)\n",
    "        data = torch.load(file_path, weights_only=False)\n",
    "\n",
    "        print(f\"Loaded data from {file_path}\")\n",
    "\n",
    "        # Remove 'scores' from data if it exists\n",
    "        if 'scores' in data:\n",
    "            del data['scores']\n",
    "\n",
    "        \n",
    "        if self.preprocess:\n",
    "            data = self.preprocess_event(data)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def preprocess_event(self, data):\n",
    "        print(\"Preprocessing data\")\n",
    "        data = self.add_edge_features(data)\n",
    "        return data\n",
    "\n",
    "    def add_edge_features(self, data):\n",
    "        edge_features = self.hparams.get(\"edge_features\", [])\n",
    "        data = handle_edge_features(data, edge_features)\n",
    "        return data\n",
    "\n",
    "def handle_edge_features(data, edge_features):\n",
    "    src, dst = data.edge_index\n",
    "    \n",
    "    if \"dr\" in edge_features and not (\"dr\" in data.keys()):\n",
    "        data.dr = data.r[dst] - data.r[src]\n",
    "\n",
    "    if \"dz\" in edge_features and not (\"dz\" in data.keys()):\n",
    "        data.dz = data.z[dst] - data.z[src]\n",
    "\n",
    "    if \"dphi\" in edge_features and not (\"dphi\" in data.keys()):\n",
    "        dphi = data.phi[dst] - data.phi[src]\n",
    "        data.dphi = torch.atan2(torch.sin(dphi), torch.cos(dphi))\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fead17-2243-4eb2-a871-4b12248d39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"stage\": \"edge_classifier\",\n",
    "    \"model\": \"QuantumInteractionGNN2\",\n",
    "    \"input_dir\": \"/users/santoshp/uiuc/quantumGNN/data/\",\n",
    "    \"stage_dir\": \"/users/santoshp/uiuc/quantumGNN/model/\",\n",
    "    \"project\": \"CTD_Quantum_2025\",\n",
    "    \"accelerator\": \"gpu\",\n",
    "    \"devices\": 1,\n",
    "    \"nodes\": 1,\n",
    "\n",
    "    # Dataset parameters\n",
    "    \"data_split\": [10, 5, 5],\n",
    "    \"dataset_class\": \"GraphDataset\",\n",
    "    \"undirected\": False,\n",
    "\n",
    "    # Weighting and truth parameters\n",
    "    \"weighting\": [\n",
    "        {\n",
    "            \"weight\": 1.0,\n",
    "            \"conditions\": {\n",
    "                \"y\": True,\n",
    "                \"pt\": [1000.0, float(\"inf\")],\n",
    "                \"nhits\": [3, float(\"inf\")],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"hard_cuts\": {\n",
    "        \"pt\": [1000.0, float(\"inf\")],\n",
    "    },\n",
    "\n",
    "    # Model parameters\n",
    "    \"edge_cut\": 0.5,\n",
    "    \"node_features\": [\"r\", \"phi\", \"z\"],\n",
    "    \"node_scales\": [1000.0, 3.14159265359, 1000.0],\n",
    "    \"edge_features\": [\"dr\", \"dphi\", \"dz\"],\n",
    "\n",
    "    # Quantum-specific parameters\n",
    "    \"n_qubits\": 2,\n",
    "    \"n_qlayers\": 1,\n",
    "    \"quantum_device\": \"default.qubit\",\n",
    "\n",
    "    # Network architecture\n",
    "    \"hidden\": 16,\n",
    "    \"n_graph_iters\": 8,\n",
    "    \"n_node_encoder_layers\": 1,\n",
    "    \"n_edge_encoder_layers\": 1,\n",
    "    \"n_node_net_layers\": 3,\n",
    "    \"n_edge_net_layers\": 3,\n",
    "    \"n_node_decoder_layers\": 1,\n",
    "    \"n_edge_decoder_layers\": 1,\n",
    "\n",
    "    # Normalization and activations\n",
    "    \"layernorm\": False,\n",
    "    \"output_layer_norm\": False,\n",
    "    \"edge_output_transform_final_layer_norm\": False,\n",
    "    \"batchnorm\": True,\n",
    "    \"output_batch_norm\": False,\n",
    "    \"edge_output_transform_final_batch_norm\": False,\n",
    "    \"bn_track_running_stats\": False,\n",
    "    \"hidden_activation\": \"ReLU\",\n",
    "    \"output_activation\": \"ReLU\",\n",
    "    \"edge_output_transform_final_activation\": None,\n",
    "\n",
    "    # Message passing options\n",
    "    \"concat\": True,\n",
    "    \"node_net_recurrent\": True,\n",
    "    \"edge_net_recurrent\": True,\n",
    "    \"in_out_diff_agg\": True,\n",
    "    \"checkpointing\": True,\n",
    "\n",
    "    # Training parameters\n",
    "    \"warmup\": 5,\n",
    "    \"lr\": 0.0001,\n",
    "    \"min_lr\": 0.00005,\n",
    "    \"factor\": 0.9,\n",
    "    \"patience\": 15,\n",
    "    \"max_epochs\": 100,\n",
    "    \"max_training_graph_size\": 2800000,\n",
    "    \"debug\": False,\n",
    "    \"num_workers\": [8, 8, 8],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181365ef-2d0a-42c0-a9ed-ff6c29253fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /users/santoshp/uiuc/quantumGNN/data/train_set/event000021044.pyg\n",
      "Preprocessing data\n",
      "DataBatch(gphi=[10374], phi=[10374], lphi=[10374], lx=[10374], z=[10374], weight=[10374], lz=[10374], region=[10374], cell_count=[10374], ly=[10374], r=[10374], eta=[10374], geta=[10374], y=[37031], hit_id=[10374], leta=[10374], cell_val=[10374], x=[10374], module_index=[10374], track_edges=[2, 9453], radius=[9453], particle_id=[9453], pt=[9453], nhits=[9453], config=[2], event_id=[1], num_nodes=10374, batch=[10374], ptr=[2], edge_index=[2, 37031], truth_map=[9453], dr=[37031], dz=[37031], dphi=[37031])\n"
     ]
    }
   ],
   "source": [
    "home_dir = '/users/santoshp/uiuc/quantumGNN/data/'\n",
    "\n",
    "test = 'test_set/'\n",
    "train = 'train_set/'\n",
    "val = 'val_set/'\n",
    "\n",
    "\n",
    "test_dataset = GraphDataset(home_dir, test, preprocess=True, hparams=hparams)\n",
    "train_dataset = GraphDataset(home_dir, train, preprocess=True, hparams=hparams)\n",
    "val_dataset = GraphDataset(home_dir, val, preprocess=True, hparams=hparams)\n",
    "\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c3d5a7-b4dd-4e50-9a72-7c46996909a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1, 'shuffle': True, 'num_workers': 0}\n",
    "train_loader = DataLoader(train_dataset,**params)  #batches join graphs instead of splitting them therefore more than train set batches will make 1 batch only \n",
    "test_loader = DataLoader(test_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98cda0d5-d065-428b-b126-937859e039eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ef6704-1b2c-4702-ad21-beae278c880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quantum_mlp(\n",
    "    input_size: int,\n",
    "    sizes: List[int],\n",
    "    hidden_activation: str = \"ReLU\",\n",
    "    output_activation: Optional[str] = None,\n",
    "    n_qubits: int = 2,\n",
    "    n_qlayers: int = 1,\n",
    "    device: str = \"default.qubit\",\n",
    "    apply_quantum_output: bool = False,\n",
    "    verbose: bool = True,\n",
    "    # Classical MLP compatibility args (ignored in quantum MLP)\n",
    "    layer_norm: bool = False,\n",
    "    output_layer_norm: bool = False,\n",
    "    batch_norm: bool = False,\n",
    "    output_batch_norm: bool = False,\n",
    "    input_dropout: float = 0.0,\n",
    "    hidden_dropout: float = 0.0,\n",
    "    track_running_stats: bool = False,\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Quantum MLP fully compatible with classical make_mlp interface.\n",
    "    Original architecture is preserved.\n",
    "    \"\"\"\n",
    "    # ------------------ original quantum MLP code ------------------\n",
    "    if n_qubits < 1:\n",
    "        raise ValueError(f\"Number of qubits must be at least 1, got {n_qubits}\")\n",
    "    if n_qlayers < 1:\n",
    "        raise ValueError(f\"Number of quantum layers must be at least 1, got {n_qlayers}\")\n",
    "    if not sizes:\n",
    "        raise ValueError(\"Sizes list cannot be empty\")\n",
    "    if input_size < 1:\n",
    "        raise ValueError(f\"Input size must be at least 1, got {input_size}\")\n",
    "    if any(size < 1 for size in sizes):\n",
    "        raise ValueError(f\"All sizes must be at least 1, got {sizes}\")\n",
    "\n",
    "    try:\n",
    "        q_device = qml.device(device, wires=n_qubits)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to initialize quantum device {device}: {str(e)}\")\n",
    "\n",
    "    def quantum_circuit(inputs, weights):\n",
    "        inputs = torch.tanh(inputs) * torch.pi\n",
    "        for i in range(n_qubits):\n",
    "            if i < inputs.shape[1]:\n",
    "                qml.RY(inputs[:, i], wires=i)\n",
    "            else:\n",
    "                qml.RY(0.0, wires=i)\n",
    "        for layer in range(n_qlayers):\n",
    "            for w in range(n_qubits):\n",
    "                qml.RX(weights[layer, w, 0], wires=w)\n",
    "                qml.RZ(weights[layer, w, 1], wires=w)\n",
    "                qml.RY(weights[layer, w, 2], wires=w)\n",
    "            for w in range(n_qubits - 1):\n",
    "                qml.CNOT(wires=[w, w + 1])\n",
    "            if n_qubits >= 2:\n",
    "                for w in range(n_qubits - 1):\n",
    "                    qml.CRZ(weights[layer, w, 3], wires=[w, w + 1])\n",
    "        return [qml.expval(qml.PauliZ(w)) for w in range(n_qubits)]\n",
    "\n",
    "    n_params_per_qubit = 4 if n_qubits >= 2 else 2\n",
    "    weight_shapes = {\"weights\": (n_qlayers, n_qubits, n_params_per_qubit)}\n",
    "\n",
    "    q_layer_1 = qml.QNode(quantum_circuit, q_device, interface=\"torch\", diff_method=\"backprop\")\n",
    "    q_layer_1 = qml.qnn.TorchLayer(q_layer_1, weight_shapes)\n",
    "    q_layer_2 = qml.QNode(quantum_circuit, q_device, interface=\"torch\", diff_method=\"backprop\")\n",
    "    q_layer_2 = qml.qnn.TorchLayer(q_layer_2, weight_shapes)\n",
    "\n",
    "    try:\n",
    "        hidden_activation_fn = getattr(nn, hidden_activation)\n",
    "    except AttributeError:\n",
    "        raise ValueError(f\"Invalid hidden_activation: {hidden_activation}\")\n",
    "    output_activation_fn = None\n",
    "    if output_activation:\n",
    "        try:\n",
    "            output_activation_fn = getattr(nn, output_activation)\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Invalid output_activation: {output_activation}\")\n",
    "\n",
    "    layers = []\n",
    "    sizes = [input_size] + sizes\n",
    "    current_size = input_size\n",
    "\n",
    "    # Minimal classical input mapping\n",
    "    if input_size != n_qubits:\n",
    "        layers.append(nn.Linear(input_size, n_qubits))\n",
    "        current_size = n_qubits\n",
    "\n",
    "    # Two quantum layers\n",
    "    layers.append(q_layer_1)\n",
    "    layers.append(q_layer_2)\n",
    "    current_size = n_qubits\n",
    "\n",
    "    # Minimal classical output mapping\n",
    "    if current_size != sizes[-1]:\n",
    "        layers.append(nn.Linear(current_size, sizes[-1]))\n",
    "        current_size = sizes[-1]\n",
    "    if output_activation_fn:\n",
    "        layers.append(output_activation_fn())\n",
    "\n",
    "    mlp_model = nn.Sequential(*layers)\n",
    "\n",
    "    # Register quantum parameters explicitly\n",
    "    for i, q_layer in enumerate([q_layer_1, q_layer_2], 1):\n",
    "        for name, param in q_layer.named_parameters():\n",
    "            mlp_model.register_parameter(f\"quantum_layer_{i}_{name}\", param)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n==== Quantum MLP Architecture ====\")\n",
    "        classical_params = 0\n",
    "        quantum_params = 0\n",
    "        for i, layer in enumerate(layers):\n",
    "            params = sum(p.numel() for p in layer.parameters()) if hasattr(layer, 'parameters') else 0\n",
    "            if isinstance(layer, qml.qnn.TorchLayer):\n",
    "                quantum_params += params\n",
    "            else:\n",
    "                classical_params += params\n",
    "            print(f\"Layer {i}: {layer}, Parameters: {params}\")\n",
    "        print(\"===================================\")\n",
    "        print(\"\\n==== Quantum MLP Parameters ====\")\n",
    "        total_params = classical_params + quantum_params\n",
    "        print(f\"Total trainable parameters: {total_params}\")\n",
    "        print(f\"Quantum parameters: {quantum_params}\")\n",
    "        print(f\"Classical parameters: {classical_params}\")\n",
    "        print(f\"Circuit: {n_qubits} qubits, {n_qlayers} layers, device={device}\")\n",
    "        print(\"===================================\")\n",
    "        print(\"===============Print-Model====================\")\n",
    "        print(mlp_model)\n",
    "        print(\"===================================\")\n",
    "\n",
    "    return mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73495111-ae81-4199-9a1c-5d8c3a424c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "class QuantumInteractionGNN2(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Set default hyperparameters\n",
    "        hparams.setdefault(\"batchnorm\", False)\n",
    "        hparams.setdefault(\"output_batch_norm\", False)\n",
    "        hparams.setdefault(\"edge_output_transform_final_batch_norm\", False)\n",
    "        hparams.setdefault(\"track_running_stats\", False)\n",
    "        hparams.setdefault(\"quantum_device\", \"default.qubit\")\n",
    "        hparams.setdefault(\"checkpointing\", True)\n",
    "        hparams.setdefault(\"concat\", True)\n",
    "        hparams.setdefault(\"in_out_diff_agg\", True)\n",
    "        hparams.setdefault(\"edge_net_recurrent\", True)\n",
    "        hparams.setdefault(\"node_net_recurrent\", True)\n",
    "\n",
    "        # Aggregation function\n",
    "        self.aggr_function = scatter_add if hparams.get(\"aggr\", \"sum\") == \"sum\" else scatter_mean\n",
    "\n",
    "        # Determine input sizes for node and edge networks\n",
    "        in_node_net = hparams[\"hidden\"] * (\n",
    "            4 if hparams[\"concat\"] and hparams[\"in_out_diff_agg\"] else\n",
    "            3 if hparams[\"concat\"] else\n",
    "            3 if hparams[\"in_out_diff_agg\"] else 2\n",
    "        )\n",
    "        in_edge_net = hparams[\"hidden\"] * 6 if hparams[\"concat\"] else hparams[\"hidden\"] * 3\n",
    "\n",
    "        # Node Encoder (Quantum MLP)\n",
    "        self.node_encoder = make_quantum_mlp(\n",
    "            input_size=len(hparams[\"node_features\"]),\n",
    "            sizes=[hparams[\"hidden\"]] * hparams[\"n_node_net_layers\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            n_qubits=hparams[\"n_qubits\"],\n",
    "            n_qlayers=hparams[\"n_qlayers\"],\n",
    "            device=hparams[\"quantum_device\"],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Edge Encoder (Quantum MLP)\n",
    "        edge_input_size = len(hparams[\"edge_features\"]) if hparams.get(\"edge_features\") else 2 * hparams[\"hidden\"]\n",
    "        self.edge_encoder = make_quantum_mlp(\n",
    "            input_size=edge_input_size,\n",
    "            sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            n_qubits=hparams[\"n_qubits\"],\n",
    "            n_qlayers=hparams[\"n_qlayers\"],\n",
    "            device=hparams[\"quantum_device\"],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Edge Network (Quantum MLP)\n",
    "        if hparams[\"edge_net_recurrent\"]:\n",
    "            self.edge_network = make_quantum_mlp(\n",
    "                input_size=in_edge_net,\n",
    "                sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "                hidden_activation=hparams[\"hidden_activation\"],\n",
    "                output_activation=hparams[\"output_activation\"],\n",
    "                n_qubits=hparams[\"n_qubits\"],\n",
    "                n_qlayers=hparams[\"n_qlayers\"],\n",
    "                device=hparams[\"quantum_device\"],\n",
    "                verbose=False,\n",
    "            )\n",
    "        else:\n",
    "            self.edge_network = nn.ModuleList([\n",
    "                make_quantum_mlp(\n",
    "                    input_size=in_edge_net,\n",
    "                    sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "                    hidden_activation=hparams[\"hidden_activation\"],\n",
    "                    output_activation=hparams[\"output_activation\"],\n",
    "                    n_qubits=hparams[\"n_qubits\"],\n",
    "                    n_qlayers=hparams[\"n_qlayers\"],\n",
    "                    device=hparams[\"quantum_device\"],\n",
    "                    verbose=False,\n",
    "                ) for _ in range(hparams[\"n_graph_iters\"])\n",
    "            ])\n",
    "\n",
    "        # Node Network (Quantum MLP)\n",
    "        if hparams[\"node_net_recurrent\"]:\n",
    "            self.node_network = make_quantum_mlp(\n",
    "                input_size=in_node_net,\n",
    "                sizes=[hparams[\"hidden\"]] * hparams[\"n_node_net_layers\"],\n",
    "                hidden_activation=hparams[\"hidden_activation\"],\n",
    "                output_activation=hparams[\"output_activation\"],\n",
    "                n_qubits=hparams[\"n_qubits\"],\n",
    "                n_qlayers=hparams[\"n_qlayers\"],\n",
    "                device=hparams[\"quantum_device\"],\n",
    "                verbose=False,\n",
    "            )\n",
    "        else:\n",
    "            self.node_network = nn.ModuleList([\n",
    "                make_quantum_mlp(\n",
    "                    input_size=in_node_net,\n",
    "                    sizes=[hparams[\"hidden\"]] * hparams[\"n_node_net_layers\"],\n",
    "                    hidden_activation=hparams[\"hidden_activation\"],\n",
    "                    output_activation=hparams[\"output_activation\"],\n",
    "                    n_qubits=hparams[\"n_qubits\"],\n",
    "                    n_qlayers=hparams[\"n_qlayers\"],\n",
    "                    device=hparams[\"quantum_device\"],\n",
    "                    verbose=False,\n",
    "                ) for _ in range(hparams[\"n_graph_iters\"])\n",
    "            ])\n",
    "\n",
    "        # Edge Decoder (Quantum MLP)\n",
    "        self.edge_decoder = make_quantum_mlp(\n",
    "            input_size=hparams[\"hidden\"],\n",
    "            sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_decoder_layers\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            output_activation=None,\n",
    "            n_qubits=hparams[\"n_qubits\"],\n",
    "            n_qlayers=hparams[\"n_qlayers\"],\n",
    "            device=hparams[\"quantum_device\"],\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Edge output transform (classical linear for logits)\n",
    "        self.edge_output_transform = nn.Linear(hparams[\"hidden\"], 1)\n",
    "\n",
    "    ###############################\n",
    "    # Training/validation/testing hooks\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        y = batch.y.float()\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Metrics\n",
    "        preds = torch.sigmoid(logits)\n",
    "        acc = ((preds > 0.5) == y).float().mean()\n",
    "        try:\n",
    "            auc = roc_auc_score(y.cpu().numpy(), preds.detach().cpu().numpy())\n",
    "        except ValueError:\n",
    "            auc = torch.tensor(0.0)  # if only one class in batch\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_auc\", auc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        print(f\" Training: Loss: {loss.item():.4f} | Acc: {acc.item():.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        y = batch.y.float()\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Metrics\n",
    "        preds = torch.sigmoid(logits)\n",
    "        acc = ((preds > 0.5) == y).float().mean()\n",
    "        try:\n",
    "            auc = roc_auc_score(y.cpu().numpy(), preds.detach().cpu().numpy())\n",
    "        except ValueError:\n",
    "            auc = torch.tensor(0.0)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_auc\", auc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        y = batch.y.float()\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # Metrics\n",
    "        preds = torch.sigmoid(logits)\n",
    "        acc = ((preds > 0.5) == y).float().mean()\n",
    "        try:\n",
    "            auc = roc_auc_score(y.cpu().numpy(), preds.detach().cpu().numpy())\n",
    "        except ValueError:\n",
    "            auc = torch.tensor(0.0)\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_auc\", auc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.get(\"lr\", 0.0001))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    ###############################\n",
    "    # Forward and message passing\n",
    "    def forward(self, batch):\n",
    "        x = torch.stack([batch[feature] for feature in self.hparams[\"node_features\"]], dim=-1).float()\n",
    "        edge_attr = torch.stack([batch[feature] for feature in self.hparams[\"edge_features\"]], dim=-1).float() if self.hparams.get(\"edge_features\") else None\n",
    "        src, dst = batch.edge_index\n",
    "        x.requires_grad = True\n",
    "        if edge_attr is not None:\n",
    "            edge_attr.requires_grad = True\n",
    "\n",
    "        # Node and edge encoding\n",
    "        if self.hparams[\"checkpointing\"]:\n",
    "            x = checkpoint(self.node_encoder, x, use_reentrant=False)\n",
    "            e = checkpoint(self.edge_encoder, edge_attr) if edge_attr is not None else checkpoint(self.edge_encoder, torch.cat([x[src], x[dst]], dim=-1))\n",
    "        else:\n",
    "            x = self.node_encoder(x)\n",
    "            e = self.edge_encoder(edge_attr if edge_attr is not None else torch.cat([x[src], x[dst]], dim=-1))\n",
    "\n",
    "        # Keep original for concat\n",
    "        if self.hparams[\"concat\"]:\n",
    "            input_x, input_e = x, e\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            if self.hparams[\"checkpointing\"] and self.hparams[\"concat\"]:\n",
    "                x = checkpoint(self.concat, x, input_x)\n",
    "                e = checkpoint(self.concat, e, input_e)\n",
    "            x, e, out = self.message_step(x, e, src, dst, i)\n",
    "            outputs.append(out)\n",
    "\n",
    "        return outputs[-1].squeeze(-1)\n",
    "\n",
    "    def message_step(self, x, e, src, dst, i=None):\n",
    "        edge_inputs = torch.cat([e, x[src], x[dst]], dim=-1)\n",
    "        if self.hparams[\"edge_net_recurrent\"]:\n",
    "            e_updated = self.edge_network(edge_inputs)\n",
    "        else:\n",
    "            e_updated = self.edge_network[i](edge_inputs)\n",
    "\n",
    "        edge_messages_src = self.aggr_function(e_updated, dst, dim=0, dim_size=x.shape[0])\n",
    "        edge_messages_dst = self.aggr_function(e_updated, src, dim=0, dim_size=x.shape[0])\n",
    "\n",
    "        if self.hparams[\"in_out_diff_agg\"]:\n",
    "            node_inputs = torch.cat([edge_messages_src, edge_messages_dst, x], dim=-1)\n",
    "        else:\n",
    "            edge_messages = edge_messages_src + edge_messages_dst\n",
    "            node_inputs = torch.cat([edge_messages, x], dim=-1)\n",
    "\n",
    "        if self.hparams[\"node_net_recurrent\"]:\n",
    "            x_updated = self.node_network(node_inputs)\n",
    "        else:\n",
    "            x_updated = self.node_network[i](node_inputs)\n",
    "\n",
    "        edge_logits = self.edge_output_transform(self.edge_decoder(e_updated))\n",
    "        return x_updated, e_updated, edge_logits\n",
    "\n",
    "    def concat(self, x, y):\n",
    "        return torch.cat([x, y], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d2c18e-21cb-496e-8f48-5c49f9d29762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "2026-01-07 03:43:01.001547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ criterion             â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ node_encoder          â”‚ Sequential        â”‚     72 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ edge_encoder          â”‚ Sequential        â”‚     72 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>â”‚ edge_network          â”‚ Sequential        â”‚    258 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>â”‚ node_network          â”‚ Sequential        â”‚    194 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>â”‚ edge_decoder          â”‚ Sequential        â”‚     98 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>â”‚ edge_output_transform â”‚ Linear            â”‚     17 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                 \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ criterion             â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ node_encoder          â”‚ Sequential        â”‚     72 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ edge_encoder          â”‚ Sequential        â”‚     72 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0mâ”‚ edge_network          â”‚ Sequential        â”‚    258 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0mâ”‚ node_network          â”‚ Sequential        â”‚    194 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0mâ”‚ edge_decoder          â”‚ Sequential        â”‚     98 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0mâ”‚ edge_output_transform â”‚ Linear            â”‚     17 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 711                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 711                                                                                                  \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 31                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 711                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 711                                                                                                  \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 31                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7238 | Acc: 0.2612 | AUC: 0.6100\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7238 | Acc: 0.2612 | AUC: 0.6100\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7278 | Acc: 0.2215 | AUC: 0.6397\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7278 | Acc: 0.2215 | AUC: 0.6397\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7271 | Acc: 0.2230 | AUC: 0.6290\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7271 | Acc: 0.2230 | AUC: 0.6290\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7249 | Acc: 0.2378 | AUC: 0.6417\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7249 | Acc: 0.2378 | AUC: 0.6417\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7226 | Acc: 0.2542 | AUC: 0.6298\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7226 | Acc: 0.2542 | AUC: 0.6298\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7250 | Acc: 0.2270 | AUC: 0.6341\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7250 | Acc: 0.2270 | AUC: 0.6341\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7257 | Acc: 0.2154 | AUC: 0.6520\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7257 | Acc: 0.2154 | AUC: 0.6520\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7226 | Acc: 0.2399 | AUC: 0.6452\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7226 | Acc: 0.2399 | AUC: 0.6452\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7242 | Acc: 0.2185 | AUC: 0.6441\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7242 | Acc: 0.2185 | AUC: 0.6441\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7189 | Acc: 0.2666 | AUC: 0.6175\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7189 | Acc: 0.2666 | AUC: 0.6175\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7231 | Acc: 0.2185 | AUC: 0.6457\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7231 | Acc: 0.2185 | AUC: 0.6457\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7221 | Acc: 0.2230 | AUC: 0.6377\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7221 | Acc: 0.2230 | AUC: 0.6377\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7212 | Acc: 0.2270 | AUC: 0.6404\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7212 | Acc: 0.2270 | AUC: 0.6404\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7170 | Acc: 0.2666 | AUC: 0.6223\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7170 | Acc: 0.2666 | AUC: 0.6223\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7176 | Acc: 0.2542 | AUC: 0.6403\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7176 | Acc: 0.2542 | AUC: 0.6403\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7185 | Acc: 0.2378 | AUC: 0.6529\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7185 | Acc: 0.2378 | AUC: 0.6529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7160 | Acc: 0.2612 | AUC: 0.6304\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7160 | Acc: 0.2612 | AUC: 0.6304\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7194 | Acc: 0.2154 | AUC: 0.6573\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7194 | Acc: 0.2154 | AUC: 0.6573\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7168 | Acc: 0.2399 | AUC: 0.6542\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7168 | Acc: 0.2399 | AUC: 0.6542\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Training: Loss: 0.7177 | Acc: 0.2215 | AUC: 0.6531\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Training: Loss: 0.7177 | Acc: 0.2215 | AUC: 0.6531\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = QuantumInteractionGNN2(hparams)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    log_every_n_steps=1,   # <-- show logs every step\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d85757-6d28-4e07-86c4-c3d0d05e00c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantumInteractionGNN2(\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (node_encoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=2, bias=True)\n",
       "    (1): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (2): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (3): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (edge_encoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=2, bias=True)\n",
       "    (1): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (2): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (3): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (edge_network): Sequential(\n",
       "    (0): Linear(in_features=96, out_features=2, bias=True)\n",
       "    (1): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (2): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (3): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (node_network): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (1): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (2): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (3): Linear(in_features=2, out_features=16, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (edge_decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "    (1): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (2): <Quantum Torch Layer: func=quantum_circuit>\n",
       "    (3): Linear(in_features=2, out_features=16, bias=True)\n",
       "  )\n",
       "  (edge_output_transform): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fa5d31-d326-4935-af25-e9cd643a4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /users/santoshp/uiuc/quantumGNN/data/val_set/event000021283.pyg\n",
      "Preprocessing data\n",
      "tensor([0.0876, 0.0861, 0.0859,  ..., 0.0879, 0.0861, 0.0866])\n",
      "36160\n",
      "tensor([0.0876, 0.0861, 0.0859,  ..., 0.0879, 0.0861, 0.0866])\n",
      "36160\n",
      "Loaded data from /users/santoshp/uiuc/quantumGNN/data/val_set/event000021346.pyg\n",
      "Preprocessing data\n",
      "tensor([0.0867, 0.0868, 0.0860,  ..., 0.0859, 0.0854, 0.0864])\n",
      "35598\n",
      "tensor([0.0867, 0.0868, 0.0860,  ..., 0.0859, 0.0854, 0.0864])\n",
      "35598\n",
      "Loaded data from /users/santoshp/uiuc/quantumGNN/data/val_set/event000021334.pyg\n",
      "Preprocessing data\n",
      "tensor([0.0867, 0.0865, 0.0858,  ..., 0.0831, 0.0818, 0.0856])\n",
      "42860\n",
      "tensor([0.0867, 0.0865, 0.0858,  ..., 0.0831, 0.0818, 0.0856])\n",
      "42860\n",
      "Loaded data from /users/santoshp/uiuc/quantumGNN/data/val_set/event000021349.pyg\n",
      "Preprocessing data\n",
      "tensor([0.0852, 0.0861, 0.0867,  ..., 0.0865, 0.0869, 0.0844])\n",
      "42357\n",
      "tensor([0.0852, 0.0861, 0.0867,  ..., 0.0865, 0.0869, 0.0844])\n",
      "42357\n",
      "Loaded data from /users/santoshp/uiuc/quantumGNN/data/val_set/event000021341.pyg\n",
      "Preprocessing data\n",
      "tensor([0.0861, 0.0865, 0.0865,  ..., 0.0864, 0.0856, 0.0856])\n",
      "41964\n",
      "tensor([0.0861, 0.0865, 0.0865,  ..., 0.0864, 0.0856, 0.0856])\n",
      "41964\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        edge_scores = model(batch)\n",
    "        print(edge_scores)\n",
    "        print(edge_scores.size(0))\n",
    "        positive_scores = edge_scores[edge_scores > 0]\n",
    "        print(positive_scores)\n",
    "        print(positive_scores.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42cbe7-93e6-405e-afaf-f459e5254e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc62cc0-dfc7-478a-94ec-5d180f44676a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8393f-5248-471f-8ef3-3e5481226248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cd3b5-a063-47e3-89fd-ded345af77a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e8ea5-103c-4f35-8858-1797cad850ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbc2dc-ac03-499f-aa48-a8e35bed7e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd970f-236b-4f8b-ab20-7bb6516dd1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
